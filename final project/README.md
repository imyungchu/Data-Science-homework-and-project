## :computer: Term Project  

comparing the accuracy of five methods to predict the number of sharing bike with whether factors, as shown in the following pictures :

#### Comparison of the model performance 


| model (Use R language to implement) | accuracy |
| ------------------------------------| -------- |
| 1. Multiple linear regression   | 0.8196657    |
| 2. Support Vector Regrssion      | 0.8242527 |
| 3. Neural Network                | 0.8536584 |
| 4. Random Forest Regression     |  0.907943 |
| 5. eXtreme Gradient Boosting    |  0.9632193|
-  neural network
![](https://i.imgur.com/KM3Rr3b.jpg)

> ### Reference
> - 支持向量迴歸(Support Vector Regression)
> https://medium.com/r-%E8%AA%9E%E8%A8%80%E8%87%AA%E5%AD%B8%E7%B3%BB%E5%88%97/r%E8%AA%9E%E8%A8%80%E8%87%AA%E5%AD%B8%E6%97%A5%E8%A8%98-20-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E4%B8%80-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E8%BF%B4%E6%AD%B8-support-vector-regression-30cd834a918
> - 隨機森林(Random Forest)
> https://medium.com/chung-yi/ml%E5%85%A5%E9%96%80-%E5%8D%81%E4%B8%83-%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-6afc24871857
> - 神經網路
> https://www.geeksforgeeks.org/how-neural-networks-are-used-for-regression-in-r-program
> ming/
> - 機器學習常勝軍 - XGBoost
> https://ithelp.ithome.com.tw/articles/10273094
> https://www.datatechnotes.com/2020/08/regression-example-with-xgboost-in-r.html
> - 資料前處理( Label encoding、 One hot encoding and frequency encoding)
> https://medium.com/@PatHuang/%E5%88%9D%E5%AD%B8python%E6%89%8B%E8%A8%98-3-%E8%B3%87%E6%96%99%E5%89%8D%E8%99%95%E7%90%86-label-encoding-one-hot-encoding-85c
> 983d63f87
